#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ANALIZADOR AVANZADO DE CONVERSACIONES DE WHATSAPP - VERSI√ìN MEJORADA 5.0
Aplicaci√≥n web optimizada con mejores visualizaciones y an√°lisis inteligente

Autor: Sistema de An√°lisis de Comunicaciones
Versi√≥n: 5.0 - Enhanced Edition con mejoras de performance y UI
"""

import streamlit as st
import pandas as pd
import re
import csv
import io
import os
import logging
import hashlib
from datetime import datetime, timedelta
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from collections import Counter, defaultdict
import time

# Configuraci√≥n de logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Verificaci√≥n segura de dependencias NLP
@st.cache_resource
def check_nlp_dependencies():
    """Verifica qu√© dependencias NLP est√°n disponibles de forma segura"""
    spacy_available = False
    textblob_available = False
    nlp_model = None
    
    try:
        from textblob import TextBlob
        test_blob = TextBlob("test text")
        _ = test_blob.sentiment.polarity
        textblob_available = True
    except Exception:
        textblob_available = False
    
    try:
        import spacy
        try:
            nlp_model = spacy.load("es_core_news_sm")
            spacy_available = True
        except OSError:
            spacy_available = False
    except ImportError:
        spacy_available = False
    
    return spacy_available, textblob_available, nlp_model

SPACY_AVAILABLE, TEXTBLOB_AVAILABLE, nlp = check_nlp_dependencies()

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="WhatsApp Analyzer 5.0 - Enhanced",
    page_icon="üîç",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personalizado mejorado
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 50%, #f093fb 100%);
        padding: 2rem;
        border-radius: 15px;
        margin-bottom: 2rem;
        color: white;
        text-align: center;
        box-shadow: 0 8px 32px 0 rgba(31, 38, 135, 0.37);
    }
    
    .metric-card {
        background: linear-gradient(145deg, #f8f9fa, #e9ecef);
        padding: 1.5rem;
        border-radius: 12px;
        border-left: 4px solid #667eea;
        margin: 0.5rem 0;
        box-shadow: 0 4px 15px 0 rgba(31, 38, 135, 0.2);
    }
    
    .alert-critical {
        background: linear-gradient(145deg, #fee, #fdd);
        border-left: 6px solid #dc3545;
        padding: 1rem;
        border-radius: 8px;
        margin: 1rem 0;
    }
    
    .alert-warning {
        background: linear-gradient(145deg, #fffbf0, #fff4d6);
        border-left: 6px solid #ffc107;
        padding: 1rem;
        border-radius: 8px;
        margin: 1rem 0;
    }
    
    .alert-info {
        background: linear-gradient(145deg, #f0f8ff, #e6f3ff);
        border-left: 6px solid #17a2b8;
        padding: 1rem;
        border-radius: 8px;
        margin: 1rem 0;
    }
    
    .detection-table {
        border: 1px solid #dee2e6;
        border-radius: 12px;
        overflow: hidden;
        margin: 1rem 0;
        box-shadow: 0 4px 15px 0 rgba(0,0,0,0.1);
    }
    
    .detection-row {
        border-bottom: 1px solid #eee;
        padding: 1rem;
        transition: background-color 0.2s;
    }
    
    .detection-row:hover {
        background-color: #f8f9fa;
    }
    
    .risk-badge-high {
        background: #dc3545;
        color: white;
        padding: 0.25rem 0.75rem;
        border-radius: 15px;
        font-size: 0.875rem;
        font-weight: bold;
    }
    
    .risk-badge-medium {
        background: #ffc107;
        color: #212529;
        padding: 0.25rem 0.75rem;
        border-radius: 15px;
        font-size: 0.875rem;
        font-weight: bold;
    }
    
    .risk-badge-low {
        background: #28a745;
        color: white;
        padding: 0.25rem 0.75rem;
        border-radius: 15px;
        font-size: 0.875rem;
        font-weight: bold;
    }
    
    .progress-container {
        background: #f8f9fa;
        border-radius: 10px;
        padding: 1rem;
        margin: 1rem 0;
    }
    
    .filter-section {
        background: linear-gradient(145deg, #f8f9fa, #e9ecef);
        padding: 1.5rem;
        border-radius: 12px;
        margin: 1rem 0;
        border: 1px solid #dee2e6;
    }
    
    .recommendation-box {
        background: linear-gradient(145deg, #e8f5e8, #d4edda);
        border: 1px solid #c3e6cb;
        border-radius: 8px;
        padding: 1rem;
        margin: 0.5rem 0;
    }
</style>
""", unsafe_allow_html=True)

class SmartTextAnalyzer:
    """Analizador de texto inteligente optimizado - Versi√≥n 5.0"""
    
    def __init__(self):
        self.spacy_available = SPACY_AVAILABLE
        self.textblob_available = TEXTBLOB_AVAILABLE
        self.nlp = nlp
        
        # Patrones mejorados
        self.negation_patterns = ["no", "nunca", "jam√°s", "nada", "tampoco", "ni", "sin"]
        self.intensity_modifiers = {
            "muy": 1.5, "super": 1.7, "extremadamente": 2.0, "bastante": 1.3,
            "algo": 0.7, "poco": 0.5, "medio": 0.8, "un poco": 0.6,
            "mucho": 1.4, "demasiado": 1.6, "incre√≠blemente": 1.8
        }
        self.positive_emotions = ["amor", "cari√±o", "besos", "abrazos", "feliz", "contento", "alegre", "genial"]
        self.negative_emotions = ["odio", "rabia", "ira", "triste", "deprimido", "enojado", "furioso", "disgusto"]
    
    def analyze_message(self, text, sender, timestamp, config, dictionary, detection_type):
        """An√°lisis principal del mensaje con mejoras de performance"""
        
        cleaned_text = self.preprocess_text(text)
        
        analysis_results = {
            'sentiment': self.analyze_sentiment(text),
            'negation': self.detect_negation_simple(cleaned_text),
            'intensity': self.calculate_intensity(text, cleaned_text),
            'emotion': self.analyze_basic_emotion(cleaned_text),
            'context': self.analyze_context_smart(cleaned_text, dictionary, detection_type),
            'temporal': self.analyze_temporal_patterns(timestamp),
            'patterns': self.detect_behavioral_patterns(cleaned_text, detection_type)
        }
        
        if self.spacy_available and self.nlp:
            analysis_results.update(self.advanced_spacy_analysis(cleaned_text))
        
        base_score = self.calculate_base_score(cleaned_text, dictionary)
        smart_score = self.calculate_contextual_score(base_score, analysis_results, detection_type)
        
        detected_words = self.get_detected_words(text, dictionary)
        explanation = self.generate_comprehensive_explanation(analysis_results, smart_score, detection_type)
        
        label = "DETECTADO" if smart_score > config['threshold'] else "NO DETECTADO"
        
        return smart_score, label, detected_words, analysis_results, explanation
    
    def preprocess_text(self, text):
        """Preprocesamiento inteligente del texto"""
        text = text.lower()
        
        emoji_patterns = {
            r'[üòçüòò‚ù§Ô∏èüíïüíñüòªü•∞üíò]': ' _expresion_amor_ ',
            r'[üò†üò°ü§¨üëøüí¢üò§]': ' _expresion_rabia_ ',
            r'[üò¢üò≠üíîüòûüòîü•∫]': ' _expresion_tristeza_ ',
            r'[üòèüòàüî•üí¶üçÜüçë]': ' _expresion_sexual_ ',
            r'[ü§Æü§¢üí©üëé]': ' _expresion_disgusto_ '
        }
        
        for pattern, replacement in emoji_patterns.items():
            text = re.sub(pattern, replacement, text)
        
        text = re.sub(r'(.)\1{3,}', r'\1\1', text)
        
        replacements = {
            r's[3e]xy': 'sexy', r'k[1i]ero': 'quiero', r'h3rm0sa': 'hermosa',
            r'b[3e]ll[4a]': 'bella', r'amor3s': 'amores', r'\bb+b+\b': 'bebe',
            r'x+d+': 'xd', r'jaj+a*': 'jaja', r'jej+e*': 'jeje'
        }
        
        for pattern, replacement in replacements.items():
            text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)
        
        return text
    
    def analyze_sentiment(self, text):
        """An√°lisis de sentimientos mejorado"""
        if self.textblob_available:
            try:
                from textblob import TextBlob
                blob = TextBlob(text)
                polarity = blob.sentiment.polarity
                subjectivity = blob.sentiment.subjectivity
                
                if polarity > 0.3:
                    interpretation = "positivo"
                elif polarity < -0.3:
                    interpretation = "negativo"
                else:
                    interpretation = "neutral"
                
                return {
                    'polarity': polarity,
                    'subjectivity': subjectivity,
                    'interpretation': interpretation,
                    'confidence': abs(polarity),
                    'method': 'textblob'
                }
            except Exception:
                pass
        
        return self.basic_sentiment_analysis(text)
    
    def basic_sentiment_analysis(self, text):
        """An√°lisis b√°sico de sentimientos sin dependencias"""
        positive_words = ["bien", "bueno", "genial", "excelente", "perfecto", "incre√≠ble", "fant√°stico", "maravilloso"]
        negative_words = ["mal", "malo", "terrible", "horrible", "awful", "pesimo", "desastre", "odioso"]
        
        text_lower = text.lower()
        positive_count = sum(1 for word in positive_words if word in text_lower)
        negative_count = sum(1 for word in negative_words if word in text_lower)
        
        if positive_count > negative_count:
            polarity = 0.5
            interpretation = "positivo"
        elif negative_count > positive_count:
            polarity = -0.5
            interpretation = "negativo"
        else:
            polarity = 0.0
            interpretation = "neutral"
        
        return {
            'polarity': polarity,
            'subjectivity': 0.5,
            'interpretation': interpretation,
            'confidence': abs(polarity),
            'method': 'basic'
        }
    
    def detect_negation_simple(self, text):
        """Detecci√≥n simple pero efectiva de negaciones"""
        words = text.split()
        negations = []
        
        for i, word in enumerate(words):
            if word in self.negation_patterns:
                context = words[i+1:i+4] if i+1 < len(words) else []
                strength = 1.0 if word in ["nunca", "jam√°s", "nada"] else 0.8
                
                negations.append({
                    'word': word,
                    'position': i,
                    'context': context,
                    'strength': strength
                })
        
        return negations
    
    def calculate_intensity(self, original_text, cleaned_text):
        """Calcula intensidad emocional del mensaje"""
        intensity_score = 1.0
        indicators = []
        
        for word, multiplier in self.intensity_modifiers.items():
            if word in cleaned_text:
                intensity_score *= multiplier
                indicators.append(f"{word} ({multiplier}x)")
        
        caps_ratio = sum(1 for c in original_text if c.isupper()) / max(len(original_text), 1)
        if caps_ratio > 0.3:
            intensity_score *= 1.4
            indicators.append(f"MAY√öSCULAS ({caps_ratio:.0%})")
        
        exclamations = original_text.count('!')
        questions = original_text.count('?')
        
        if exclamations > 1:
            multiplier = 1 + (exclamations - 1) * 0.15
            intensity_score *= multiplier
            indicators.append(f"!√ó{exclamations}")
        
        if questions > 2:
            intensity_score *= 1.2
            indicators.append(f"?√ó{questions}")
        
        repetition_pattern = r'(.)\1{2,}'
        if re.search(repetition_pattern, original_text):
            intensity_score *= 1.2
            indicators.append("repeticiones")
        
        return {
            'score': min(intensity_score, 3.0),
            'indicators': indicators
        }
    
    def analyze_basic_emotion(self, text):
        """An√°lisis b√°sico de emociones"""
        positive_count = sum(1 for word in self.positive_emotions if word in text)
        negative_count = sum(1 for word in self.negative_emotions if word in text)
        
        emotion_expressions = {
            '_expresion_amor_': 'rom√°ntico',
            '_expresion_rabia_': 'agresivo',
            '_expresion_tristeza_': 'melanc√≥lico',
            '_expresion_sexual_': 'sexual',
            '_expresion_disgusto_': 'desprecio'
        }
        
        detected_expressions = []
        for expr, emotion in emotion_expressions.items():
            if expr in text:
                detected_expressions.append(emotion)
        
        if positive_count > negative_count:
            return {'tone': 'positivo', 'strength': positive_count, 'expressions': detected_expressions}
        elif negative_count > positive_count:
            return {'tone': 'negativo', 'strength': negative_count, 'expressions': detected_expressions}
        else:
            return {'tone': 'neutral', 'strength': 0, 'expressions': detected_expressions}
    
    def analyze_context_smart(self, text, dictionary, detection_type):
        """An√°lisis de contexto mejorado"""
        context_analysis = {
            'laboral': 0, 'rom√°ntico': 0, 'familiar': 0, 'agresivo': 0,
            'sexual': 0, 'social': 0, 'temporal': 0
        }
        
        context_terms = {
            'laboral': ['jefe', 'trabajo', 'oficina', 'reuni√≥n', 'proyecto', 'empresa', 'ascenso', 'salario'],
            'rom√°ntico': ['amor', 'cari√±o', 'besos', 'pareja', 'novio', 'novia', 'cita', 'te amo'],
            'familiar': ['familia', 'pap√°', 'mam√°', 'hermano', 'hermana', 'hijo', 'hija', 'casa', 'hogar'],
            'agresivo': ['odio', 'matar', 'golpear', 'destruir', 'venganza', 'rabia', 'pelea'],
            'sexual': dictionary.get('high_risk', []) + dictionary.get('medium_risk', []),
            'social': ['amigos', 'fiesta', 'grupo', 'clase', 'escuela', 'universidad', 'compa√±eros'],
            'temporal': ['noche', 'madrugada', 'tarde', 'ma√±ana', 'despu√©s', 'luego', 'pronto']
        }
        
        for context_type, terms in context_terms.items():
            matches = sum(1 for term in terms if term in text)
            max_expected = 3
            context_analysis[context_type] = min(matches / max_expected, 1.0)
        
        return context_analysis
    
    def analyze_temporal_patterns(self, timestamp):
        """An√°lisis de patrones temporales"""
        try:
            hour_match = re.search(r'(\d{1,2}):(\d{2})', timestamp)
            if hour_match:
                hour = int(hour_match.group(1))
                
                if 6 <= hour <= 12:
                    period = "ma√±ana"
                elif 12 <= hour <= 18:
                    period = "tarde"
                elif 18 <= hour <= 22:
                    period = "noche"
                else:
                    period = "madrugada"
                
                return {
                    'hour': hour,
                    'period': period,
                    'is_night': hour >= 22 or hour <= 6,
                    'is_late': hour >= 23 or hour <= 5,
                    'is_work_hours': 9 <= hour <= 18
                }
        except Exception:
            pass
        
        return {
            'hour': None, 'period': 'desconocido', 'is_night': False,
            'is_late': False, 'is_work_hours': False
        }
    
    def detect_behavioral_patterns(self, text, detection_type):
        """Detecta patrones de comportamiento espec√≠ficos"""
        patterns = {
            'Acoso Sexual': [
                r'\b(solos?\s+(?:tu\s+y\s+yo|nosotros))\b',
                r'\b(secreto\s+(?:entre|nuestro))\b',
                r'\b(no\s+(?:le\s+)?dig[au]s?)\b',
                r'\b(encuentro\s+privado)\b'
            ],
            'CyberBullying': [
                r'\b(todos\s+(?:te\s+odian|se\s+r√≠en))\b',
                r'\b(nadie\s+(?:te\s+quiere|te\s+aguanta))\b',
                r'\b(eres\s+(?:un|una)\s+\w+)\b',
                r'\b(no\s+sirves?)\b'
            ],
            'Infidelidades': [
                r'\b(no\s+(?:puede|debe)\s+saber)\b',
                r'\b(entre\s+nosotros)\b',
                r'\b(tengo\s+(?:pareja|esposo|esposa))\b',
                r'\b(es\s+complicado)\b'
            ]
        }
        
        detected_patterns = []
        if detection_type in patterns:
            for pattern in patterns[detection_type]:
                matches = re.findall(pattern, text, re.IGNORECASE)
                if matches:
                    detected_patterns.extend(matches)
        
        return detected_patterns
    
    def advanced_spacy_analysis(self, text):
        """An√°lisis avanzado con spaCy si est√° disponible"""
        if not self.spacy_available or not self.nlp:
            return {}
        
        try:
            doc = self.nlp(text)
            
            entities = {
                'persons': [ent.text for ent in doc.ents if ent.label_ in ["PER", "PERSON"]],
                'locations': [ent.text for ent in doc.ents if ent.label_ in ["LOC", "GPE"]],
                'organizations': [ent.text for ent in doc.ents if ent.label_ == "ORG"]
            }
            
            pos_tags = [token.pos_ for token in doc]
            verb_count = pos_tags.count('VERB')
            noun_count = pos_tags.count('NOUN')
            adj_count = pos_tags.count('ADJ')
            
            return {
                'entities': entities,
                'grammar': {
                    'verbs': verb_count,
                    'nouns': noun_count,
                    'adjectives': adj_count,
                    'complexity': len(set(pos_tags)) / len(pos_tags) if pos_tags else 0
                },
                'spacy_available': True
            }
        except Exception:
            return {'spacy_available': False}
    
    def calculate_base_score(self, text, dictionary):
        """Calcula puntuaci√≥n base usando el diccionario"""
        high_matches = sum(1 for term in dictionary.get('high_risk', []) if term in text)
        medium_matches = sum(1 for term in dictionary.get('medium_risk', []) if term in text)
        context_matches = sum(1 for term in dictionary.get('context_phrases', []) if term in text)
        work_matches = sum(1 for term in dictionary.get('work_context', []) if term in text)
        
        total_terms = (len(dictionary.get('high_risk', [])) + 
                      len(dictionary.get('medium_risk', [])))
        
        if total_terms == 0:
            return 0
        
        score = ((high_matches * 0.8) + 
                (medium_matches * 0.4) + 
                (context_matches * 0.3) + 
                (work_matches * 0.2)) / max(total_terms, 1)
        
        return min(score, 1.0)
    
    def calculate_contextual_score(self, base_score, analysis, detection_type):
        """Calcula puntuaci√≥n final considerando contexto"""
        score = base_score
        
        negations = analysis['negation']
        for negation in negations:
            reduction = negation['strength'] * 0.4
            score *= (1 - reduction)
        
        intensity = analysis['intensity']['score']
        score *= intensity
        
        sentiment = analysis['sentiment']
        if detection_type == "Acoso Sexual":
            if sentiment['polarity'] > 0.2:
                score *= 1.2
        elif detection_type == "CyberBullying":
            if sentiment['polarity'] < -0.3:
                score *= 1.4
        elif detection_type == "Infidelidades":
            if abs(sentiment['polarity']) > 0.3:
                score *= 1.2
        
        context = analysis['context']
        if detection_type == "Acoso Sexual":
            if context['laboral'] > 0.5 and context['sexual'] > 0.3:
                score *= 1.8
            elif context['rom√°ntico'] > 0.6:
                score *= 0.7
        
        elif detection_type == "CyberBullying":
            if context['agresivo'] > 0.4:
                score *= 1.6
            if context['social'] > 0.3:
                score *= 1.3
        
        elif detection_type == "Infidelidades":
            if context['rom√°ntico'] > 0.4:
                score *= 1.4
            temporal = analysis['temporal']
            if temporal['is_night']:
                score *= 1.2
        
        patterns = analysis['patterns']
        if patterns:
            score *= (1 + len(patterns) * 0.2)
        
        return min(score, 1.0)
    
    def get_detected_words(self, text, dictionary):
        """Obtiene palabras detectadas del diccionario"""
        text_lower = text.lower()
        detected = []
        
        for category, terms in dictionary.items():
            for term in terms:
                if term.lower() in text_lower and term not in detected:
                    detected.append(term)
        
        return detected
    
    def generate_comprehensive_explanation(self, analysis, score, detection_type):
        """Genera explicaci√≥n detallada del an√°lisis"""
        explanations = []
        
        sentiment = analysis['sentiment']
        if sentiment['confidence'] > 0.3:
            explanations.append(f"Sentimiento {sentiment['interpretation']} ({sentiment['polarity']:.2f})")
        
        negations = analysis['negation']
        if negations:
            explanations.append(f"Negaciones: {len(negations)}")
        
        intensity = analysis['intensity']
        if intensity['score'] > 1.3:
            explanations.append(f"Alta intensidad ({intensity['score']:.1f}x)")
        
        context = analysis['context']
        max_context = max(context.items(), key=lambda x: x[1])
        if max_context[1] > 0.4:
            explanations.append(f"Contexto {max_context[0]}")
        
        emotion = analysis['emotion']
        if emotion['expressions']:
            explanations.append(f"Expresiones: {', '.join(emotion['expressions'])}")
        
        patterns = analysis['patterns']
        if patterns:
            explanations.append(f"Patrones detectados: {len(patterns)}")
        
        temporal = analysis['temporal']
        if temporal['is_night']:
            explanations.append("Horario nocturno")
        
        method = "NLP completo" if self.spacy_available else "An√°lisis inteligente"
        if sentiment['method'] == 'textblob':
            method += " + TextBlob"
        
        explanation_text = " | ".join(explanations) if explanations else "An√°lisis b√°sico"
        return f"{explanation_text} ({method})"

# Funciones auxiliares mejoradas
@st.cache_data(ttl=3600)
def analyze_messages_batch(messages_hash, dictionary_hash, config_hash):
    """Cache de an√°lisis para evitar reprocesamiento"""
    return None

def calculate_advanced_metrics(results_df):
    """Calcula m√©tricas avanzadas para mejor insights"""
    metrics = {}
    
    if 'timestamp' in results_df.columns and len(results_df) > 0:
        try:
            results_df['parsed_date'] = pd.to_datetime(results_df['timestamp'], errors='coerce', infer_datetime_format=True)
            results_df_with_dates = results_df.dropna(subset=['parsed_date'])
            
            if len(results_df_with_dates) > 0:
                results_df_with_dates['hour'] = results_df_with_dates['parsed_date'].dt.hour
                hourly_risk = results_df_with_dates.groupby('hour')['risk_score'].mean()
                if len(hourly_risk) > 0:
                    metrics['peak_risk_hour'] = hourly_risk.idxmax()
                    metrics['lowest_risk_hour'] = hourly_risk.idxmin()
        except Exception:
            pass
    
    detected_words_list = results_df[results_df['label'] == 'DETECTADO']['detected_words'].str.cat(sep=', ')
    if detected_words_list:
        word_freq = Counter([word.strip() for word in detected_words_list.split(',') if word.strip()])
        metrics['top_risk_words'] = dict(word_freq.most_common(5))
    
    if len(results_df) > 10:
        risk_trend = results_df['risk_score'].rolling(window=10).mean().diff().iloc[-1]
        metrics['risk_trend'] = 'increasing' if risk_trend > 0 else 'decreasing'
    
    return metrics

def generate_smart_alerts(results_df, detection_type):
    """Genera alertas inteligentes basadas en patrones"""
    alerts = []
    
    detected_df = results_df[results_df['label'] == 'DETECTADO']
    
    if len(detected_df) > 0:
        detection_rate = len(detected_df) / len(results_df)
        
        if detection_rate > 0.3:
            alerts.append({
                'level': 'critical',
                'message': f'‚ö†Ô∏è CR√çTICO: {len(detected_df)} detecciones de {len(results_df)} mensajes ({detection_rate*100:.1f}%)',
                'type': 'high_frequency'
            })
        elif detection_rate > 0.15:
            alerts.append({
                'level': 'warning',
                'message': f'üîî ADVERTENCIA: {len(detected_df)} detecciones de {len(results_df)} mensajes ({detection_rate*100:.1f}%)',
                'type': 'medium_frequency'
            })
        
        sender_counts = detected_df['sender'].value_counts()
        if len(sender_counts) > 0:
            dominant_sender_pct = sender_counts.iloc[0] / len(detected_df) * 100
            if dominant_sender_pct > 70:
                alerts.append({
                    'level': 'info',
                    'message': f'üë§ REMITENTE DOMINANTE: {sender_counts.index[0]} ({dominant_sender_pct:.1f}% de detecciones)',
                    'type': 'sender_concentration'
                })
    
    return alerts

def generate_recommendations(results_df, detection_type):
    """Genera recomendaciones espec√≠ficas basadas en los resultados"""
    recommendations = []
    
    detection_rate = len(results_df[results_df['label'] == 'DETECTADO']) / len(results_df) if len(results_df) > 0 else 0
    
    if detection_rate > 0.3:
        recommendations.append("üö® ALTA PRIORIDAD: Revisar inmediatamente las conversaciones detectadas")
        recommendations.append("üìû Considerar contactar a un profesional especializado")
    elif detection_rate > 0.1:
        recommendations.append("‚ö†Ô∏è ATENCI√ìN: Monitorear la situaci√≥n de cerca")
        recommendations.append("üìù Documentar evidencias adicionales")
    else:
        recommendations.append("‚úÖ SITUACI√ìN ESTABLE: Continuar monitoreo rutinario")
    
    if detection_type == "Acoso Sexual":
        recommendations.append("üè¢ Si es contexto laboral, reportar a RRHH")
        recommendations.append("‚öñÔ∏è Considerar asesor√≠a legal si hay evidencia clara")
    elif detection_type == "CyberBullying":
        recommendations.append("üè´ Si involucra menores, contactar autoridades escolares")
        recommendations.append("üõ°Ô∏è Implementar medidas de protecci√≥n digital")
    elif detection_type == "Infidelidades":
        recommendations.append("üí¨ Considerar terapia de pareja si es apropiado")
        recommendations.append("ü§ù Buscar mediaci√≥n profesional")
    
    return recommendations

def create_enhanced_metric_dashboard(results_df):
    """Dashboard de m√©tricas mejorado"""
    col1, col2, col3, col4, col5 = st.columns(5)
    
    total = len(results_df)
    detected = len(results_df[results_df['label'] == 'DETECTADO'])
    percentage = (detected / total) * 100 if total > 0 else 0
    avg_risk = results_df['risk_score'].mean()
    max_risk = results_df['risk_score'].max()
    
    with col1:
        st.metric(
            "üì± Total Mensajes", 
            f"{total:,}",
            help="N√∫mero total de mensajes analizados"
        )
    
    with col2:
        delta_color = "inverse" if detected > 0 else "normal"
        st.metric(
            "üéØ Detectados", 
            f"{detected:,}",
            delta=f"{percentage:.1f}%",
            delta_color=delta_color,
            help="Mensajes que superaron el umbral de detecci√≥n"
        )
    
    with col3:
        if percentage > 30:
            risk_level = "üî¥ CR√çTICO"
        elif percentage > 15:
            risk_level = "üü° MEDIO"
        elif percentage > 5:
            risk_level = "üü† BAJO"
        else:
            risk_level = "üü¢ M√çNIMO"
        
        st.metric(
            f"{risk_level}", 
            f"{percentage:.1f}%",
            help="Porcentaje de detecciones sobre el total"
        )
    
    with col4:
        st.metric(
            "‚öñÔ∏è Riesgo Promedio", 
            f"{avg_risk:.3f}",
            help="Puntuaci√≥n promedio de riesgo (0.0 - 1.0)"
        )
    
    with col5:
        st.metric(
            "üìä Riesgo M√°ximo", 
            f"{max_risk:.3f}",
            help="Puntuaci√≥n m√°s alta encontrada"
        )

def create_advanced_filters():
    """Filtros avanzados para los resultados"""
    with st.expander("üîç **Filtros Avanzados**", expanded=False):
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.subheader("üë• Remitentes")
            sender_filter = st.multiselect(
                "Seleccionar remitentes:",
                options=[],  # Se llenar√° din√°micamente
                help="Filtrar por remitentes espec√≠ficos"
            )
        
        with col2:
            st.subheader("‚öñÔ∏è Nivel de Riesgo")
            risk_range = st.slider(
                "Rango de riesgo:",
                min_value=0.0,
                max_value=1.0,
                value=(0.0, 1.0),
                step=0.05,
                help="Filtrar por puntuaci√≥n de riesgo"
            )
        
        with col3:
            st.subheader("üîç B√∫squeda")
            word_search = st.text_input(
                "Buscar palabra:",
                placeholder="Ej: sexy, amor, secreto...",
                help="Buscar en contenido de mensajes"
            )
            
            case_sensitive = st.checkbox("Distinguir may√∫sculas/min√∫sculas")
        
        return {
            'sender_filter': sender_filter,
            'risk_range': risk_range,
            'word_search': word_search,
            'case_sensitive': case_sensitive
        }

def create_enhanced_detections_table(detected_df, show_explanations=True, max_results=50):
    """Tabla mejorada para mostrar detecciones con estilo similar a la exportaci√≥n"""
    
    if len(detected_df) == 0:
        st.info("üìä No hay detecciones que mostrar con los filtros actuales")
        return
    
    # Preparar datos para la tabla
    table_data = []
    
    for idx, row in detected_df.head(max_results).iterrows():
        # Determinar nivel de riesgo
        if row['risk_score'] > 0.8:
            risk_level = "ALTO"
            risk_color = "üî¥"
            risk_class = "high"
        elif row['risk_score'] > 0.6:
            risk_level = "MEDIO"
            risk_color = "üü°"
            risk_class = "medium"
        else:
            risk_level = "BAJO"
            risk_color = "üü¢"
            risk_class = "low"
        
        # Truncar mensaje para la tabla
        message_preview = row['message'][:100] + "..." if len(row['message']) > 100 else row['message']
        
        table_data.append({
            'ID': len(table_data) + 1,
            'Fecha/Hora': row['timestamp'],
            'Remitente': row['sender'],
            'Mensaje': message_preview,
            'Puntuaci√≥n': f"{row['risk_score']:.3f}",
            'Nivel': f"{risk_color} {risk_level}",
            'T√©rminos': row['detected_words'] if row['detected_words'] else "N/A",
            'An√°lisis': row['explanation'] if show_explanations else "N/A"
        })
    
    # Crear DataFrame para la tabla
    table_df = pd.DataFrame(table_data)
    
    # Mostrar informaci√≥n de la tabla
    st.markdown(f"""
    <div class="detection-table">
        <div style="padding: 1rem; background: linear-gradient(145deg, #f8f9fa, #e9ecef); border-bottom: 1px solid #dee2e6;">
            <h4 style="margin: 0; color: #495057;">üîç Detecciones Encontradas</h4>
            <p style="margin: 0.5rem 0 0 0; color: #6c757d;">
                Mostrando {len(table_data)} de {len(detected_df)} detecciones totales
            </p>
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # Configurar la tabla con formato
    st.dataframe(
        table_df,
        use_container_width=True,
        height=600,
        column_config={
            "ID": st.column_config.NumberColumn(
                "ID",
                width="small",
                help="N√∫mero de detecci√≥n"
            ),
            "Fecha/Hora": st.column_config.TextColumn(
                "üìÖ Fecha/Hora",
                width="medium",
                help="Momento del mensaje"
            ),
            "Remitente": st.column_config.TextColumn(
                "üë§ Remitente",
                width="small",
                help="Quien envi√≥ el mensaje"
            ),
            "Mensaje": st.column_config.TextColumn(
                "üí¨ Mensaje",
                width="large",
                help="Contenido del mensaje (vista previa)"
            ),
            "Puntuaci√≥n": st.column_config.TextColumn(
                "‚öñÔ∏è Puntuaci√≥n",
                width="small",
                help="Nivel de riesgo calculado (0.0-1.0)"
            ),
            "Nivel": st.column_config.TextColumn(
                "üéØ Nivel",
                width="small",
                help="Clasificaci√≥n del riesgo"
            ),
            "T√©rminos": st.column_config.TextColumn(
                "üîç T√©rminos",
                width="medium",
                help="Palabras clave detectadas"
            ),
            "An√°lisis": st.column_config.TextColumn(
                "üß† An√°lisis",
                width="large",
                help="Explicaci√≥n del an√°lisis realizado"
            ) if show_explanations else None
        },
        hide_index=True
    )
    
    # Mostrar algunas estad√≠sticas adicionales de la tabla
    with st.expander("üìä **Estad√≠sticas de esta vista**"):
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            high_risk = len([d for d in table_data if "ALTO" in d['Nivel']])
            st.metric("üî¥ Alto Riesgo", high_risk)
        
        with col2:
            medium_risk = len([d for d in table_data if "MEDIO" in d['Nivel']])
            st.metric("üü° Riesgo Medio", medium_risk)
        
        with col3:
            low_risk = len([d for d in table_data if "BAJO" in d['Nivel']])
            st.metric("üü¢ Riesgo Bajo", low_risk)
        
        with col4:
            avg_score = sum(float(d['Puntuaci√≥n']) for d in table_data) / len(table_data)
            st.metric("üìä Promedio", f"{avg_score:.3f}")

def create_enhanced_visualizations(results_df, detection_type):
    """Visualizaciones mejoradas de los resultados"""
    
    detected_df = results_df[results_df['label'] == 'DETECTADO']
    
    # Primera fila: Distribuci√≥n y evoluci√≥n
    col1, col2 = st.columns(2)
    
    with col1:
        # Histograma de distribuci√≥n de riesgo mejorado
        fig_hist = px.histogram(
            results_df, 
            x='risk_score', 
            nbins=30,
            title=f'üìä Distribuci√≥n de Puntuaci√≥n de Riesgo - {detection_type}',
            labels={'risk_score': 'Puntuaci√≥n de Riesgo', 'count': 'Cantidad de Mensajes'},
            color_discrete_sequence=['#667eea'],
            opacity=0.7
        )
        
        # L√≠neas de referencia mejoradas
        fig_hist.add_vline(x=0.45, line_dash="dot", line_color="green", 
                          annotation_text="Sensibilidad Alta", annotation_position="top")
        fig_hist.add_vline(x=0.60, line_dash="dash", line_color="orange", 
                          annotation_text="Sensibilidad Media", annotation_position="top")
        fig_hist.add_vline(x=0.75, line_dash="solid", line_color="red", 
                          annotation_text="Sensibilidad Baja", annotation_position="top")
        
        # Zona de detecciones
        if len(detected_df) > 0:
            min_detected = detected_df['risk_score'].min()
            fig_hist.add_vrect(
                x0=min_detected, x1=1.0,
                fillcolor="rgba(255, 0, 0, 0.1)",
                annotation_text="Zona de Detecciones",
                annotation_position="top"
            )
        
        fig_hist.update_layout(
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)',
            showlegend=False
        )
        st.plotly_chart(fig_hist, use_container_width=True)
    
    with col2:
        if len(detected_df) > 0:
            # Gr√°fico de detecciones por remitente mejorado
            detections_by_sender = detected_df['sender'].value_counts()
            
            if len(detections_by_sender) > 1:
                fig_pie = px.pie(
                    values=detections_by_sender.values,
                    names=detections_by_sender.index,
                    title=f'üéØ Detecciones por Remitente - {detection_type}',
                    color_discrete_sequence=px.colors.qualitative.Set3
                )
                fig_pie.update_traces(textposition='inside', textinfo='percent+label')
                fig_pie.update_layout(
                    plot_bgcolor='rgba(0,0,0,0)',
                    paper_bgcolor='rgba(0,0,0,0)',
                )
                st.plotly_chart(fig_pie, use_container_width=True)
            else:
                # Gr√°fico alternativo para un solo remitente
                sender_stats = results_df.groupby('sender').agg({
                    'risk_score': ['count', 'mean', 'max'],
                    'label': lambda x: (x == 'DETECTADO').sum()
                }).round(3)
                sender_stats.columns = ['Total', 'Promedio', 'M√°ximo', 'Detectados']
                
                fig_bar = px.bar(
                    x=sender_stats.index,
                    y=sender_stats['Detectados'],
                    title=f'üéØ Detecciones por Remitente - {detection_type}',
                    labels={'x': 'Remitente', 'y': 'Detecciones'},
                    color=sender_stats['Detectados'],
                    color_continuous_scale='Reds'
                )
                fig_bar.update_layout(
                    plot_bgcolor='rgba(0,0,0,0)',
                    paper_bgcolor='rgba(0,0,0,0)',
                    showlegend=False
                )
                st.plotly_chart(fig_bar, use_container_width=True)
        else:
            st.info("üìä No hay detecciones para visualizar")
    
    # Segunda fila: Timeline y patrones temporales
    if len(detected_df) > 0:
        st.subheader("üìÖ An√°lisis Temporal")
        
        try:
            # Timeline de detecciones
            detected_df_copy = detected_df.copy()
            detected_df_copy['parsed_date'] = pd.to_datetime(detected_df_copy['timestamp'], errors='coerce', infer_datetime_format=True)
            detected_df_with_dates = detected_df_copy.dropna(subset=['parsed_date'])
            
            if len(detected_df_with_dates) > 0:
                col1, col2 = st.columns(2)
                
                with col1:
                    # Timeline diario
                    daily_counts = detected_df_with_dates.groupby(detected_df_with_dates['parsed_date'].dt.date).size().reset_index()
                    daily_counts.columns = ['date', 'count']
                    
                    if len(daily_counts) > 1:
                        fig_timeline = px.line(
                            daily_counts,
                            x='date',
                            y='count',
                            title='üìà Evoluci√≥n de Detecciones por D√≠a',
                            markers=True,
                            color_discrete_sequence=['#e74c3c']
                        )
                        fig_timeline.update_layout(
                            plot_bgcolor='rgba(0,0,0,0)',
                            paper_bgcolor='rgba(0,0,0,0)',
                            xaxis_title="Fecha",
                            yaxis_title="N√∫mero de Detecciones"
                        )
                        st.plotly_chart(fig_timeline, use_container_width=True)
                    else:
                        st.info("üìä Todas las detecciones ocurrieron en el mismo d√≠a")
                
                with col2:
                    # Distribuci√≥n por hora del d√≠a
                    detected_df_with_dates['hour'] = detected_df_with_dates['parsed_date'].dt.hour
                    hourly_counts = detected_df_with_dates['hour'].value_counts().sort_index()
                    
                    fig_hourly = px.bar(
                        x=hourly_counts.index,
                        y=hourly_counts.values,
                        title='üïê Detecciones por Hora del D√≠a',
                        labels={'x': 'Hora', 'y': 'Detecciones'},
                        color=hourly_counts.values,
                        color_continuous_scale='Oranges'
                    )
                    fig_hourly.update_layout(
                        plot_bgcolor='rgba(0,0,0,0)',
                        paper_bgcolor='rgba(0,0,0,0)',
                        showlegend=False,
                        xaxis=dict(tickmode='linear', tick0=0, dtick=2)
                    )
                    st.plotly_chart(fig_hourly, use_container_width=True)
            else:
                st.info("‚è∞ No se pudieron parsear las fechas para el an√°lisis temporal")
        except Exception as e:
            st.info(f"‚è∞ No se pudo generar an√°lisis temporal: {str(e)}")

def setup_sensitivity(level, custom_threshold=None):
    """Configura niveles de sensibilidad"""
    configs = {
        'baja': {
            'threshold': 0.75, 'high_weight': 0.6, 'medium_weight': 0.2, 
            'context_weight': 0.4, 'work_weight': 0.3, 'bonus': 0.1
        },
        'media': {
            'threshold': 0.60, 'high_weight': 0.7, 'medium_weight': 0.3,
            'context_weight': 0.5, 'work_weight': 0.4, 'bonus': 0.15
        },
        'alta': {
            'threshold': 0.45, 'high_weight': 0.8, 'medium_weight': 0.4,
            'context_weight': 0.6, 'work_weight': 0.5, 'bonus': 0.2
        }
    }
    
    config = configs.get(level, configs['media'])
    if custom_threshold is not None:
        config['threshold'] = custom_threshold
    return config

def validate_whatsapp_file(content):
    """Validaci√≥n m√°s robusta de archivos de WhatsApp"""
    patterns = [
        r'\d{1,2}/\d{1,2}/\d{2,4}.*\d{1,2}:\d{2}.*-.*:',  # Formato est√°ndar
        r'\[\d{1,2}/\d{1,2}/\d{2,4}.*\d{1,2}:\d{2}.*\].*:',  # Con corchetes
        r'\d{1,2}-\d{1,2}-\d{2,4}.*\d{1,2}:\d{2}.*-.*:'  # Con guiones
    ]
    
    total_lines = len(content.split('\n'))
    matches = 0
    
    for pattern in patterns:
        pattern_matches = len(re.findall(pattern, content))
        matches = max(matches, pattern_matches)
    
    confidence = matches / max(total_lines, 1) if total_lines > 0 else 0
    
    if confidence > 0.1:  # Al menos 10% de l√≠neas parecen mensajes
        return True, f"Formato WhatsApp detectado (confianza: {confidence:.1%})"
    else:
        return False, f"No parece ser un archivo de WhatsApp v√°lido (confianza: {confidence:.1%})"

def extract_messages_from_text(content):
    """Extrae mensajes de texto de WhatsApp con parsing robusto mejorado"""
    patterns = [
        # Formato Android com√∫n con AM/PM
        r'(\d{1,2}/\d{1,2}/\d{2,4},\s\d{1,2}:\d{2}\s[ap]\.?\s?m\.?)\s*-\s*([^:]+?):\s*(.+)',
        # Formato con corchetes
        r'\[(\d{1,2}/\d{1,2}/\d{2,4}(?:,|\s)\s*\d{1,2}:\d{2}(?::\d{2})?(?:\s*[APap][Mm])?)\]\s*([^:]+?):\s*(.+)',
        # Formato simple sin AM/PM
        r'(\d{1,2}/\d{1,2}/\d{2,4}\s+\d{1,2}:\d{2}(?:\s*[APap][Mm])?)\s*-\s*([^:]+?):\s*(.+)',
        # Formato ISO con coma
        r'(\d{1,2}/\d{1,2}/\d{4},\s*\d{1,2}:\d{2})\s*-\s*([^:]+?):\s*(.+)',
        # Formato alternativo con gui√≥n
        r'(\d{1,2}-\d{1,2}-\d{2,4}\s+\d{1,2}:\d{2})\s*-\s*([^:]+?):\s*(.+)'
    ]
    
    best_pattern_matches = []
    
    for pattern in patterns:
        matches = re.findall(pattern, content, re.MULTILINE | re.IGNORECASE)
        if matches:
            clean_matches = []
            for match in matches:
                timestamp = match[0].strip()
                sender = match[1].strip()
                message = match[2].strip()
                
                # Filtrar mensajes del sistema y multimedia
                system_messages = [
                    '<multimedia omitido>', '<media omitted>', 'se uni√≥ usando', 
                    'cambi√≥ el asunto', 'elimin√≥ este mensaje', 'mensaje eliminado',
                    'left', 'joined', 'changed subject to', 'created group',
                    'added', 'removed', 'security code changed'
                ]
                
                if not message or any(sys_msg in message.lower() for sys_msg in system_messages):
                    continue
                
                # Validar que el sender no sea muy largo (probable error de parsing)
                if len(sender) > 50:
                    continue
                
                # Validar que no sea una l√≠nea de continuaci√≥n
                if len(message) < 5:
                    continue
                
                clean_matches.append((timestamp, sender, message))
            
            if len(clean_matches) > len(best_pattern_matches):
                best_pattern_matches = clean_matches
    
    return best_pattern_matches

def get_predefined_dictionaries():
    """Retorna diccionarios predefinidos mejorados"""
    return {
        "Acoso Sexual": {
            'high_risk': [
                "desnuda", "desnudo", "fotos √≠ntimas", "sexo", "sexual", "tocarte", 
                "te quiero tocar", "quiero verte", "excitado", "excitada", "cuerpo",
                "te deseo", "sexy", "sensual", "provocativa", "cama", "dormir juntos",
                "masaje", "besos", "caricias", "intimidad", "placer", "fantas√≠a",
                "seducir", "tentaci√≥n", "er√≥tico", "voluptuosa", "cachonda", "caliente"
            ],
            'medium_risk': [
                "atractiva", "atractivo", "guapa", "guapo", "bonita", "bonito",
                "nena", "nene", "beb√©", "cari√±o", "amor", "coraz√≥n", "linda", "hermosa",
                "preciosa", "bella", "encantadora", "seductora", "divina", "diosa",
                "princesa", "reina", "dulzura", "ternura"
            ],
            'context_phrases': [
                "solos", "solas", "hotel", "privado", "secreto", "nadie", "no le digas",
                "entre nosotros", "nuestro secreto", "me gustas", "me encanta",
                "encuentro privado", "cita secreta", "momento √≠ntimo", "lugar reservado",
                "cuando estemos solos", "sin que nadie sepa"
            ],
            'work_context': [
                "jefe", "jefa", "supervisor", "gerente", "director", "ascenso",
                "promoci√≥n", "evaluaci√≥n", "contrato", "reconocimiento", "bono",
                "reuni√≥n privada", "horas extra", "viaje de negocios", "despu√©s del trabajo",
                "oficina", "despacho", "proyecto", "empresa"
            ]
        },
        "CyberBullying": {
            'high_risk': [
                "idiota", "est√∫pido", "imb√©cil", "retrasado", "in√∫til", "basura",
                "escoria", "pat√©tico", "perdedor", "fracasado", "nadie te quiere",
                "todos te odian", "eres repugnante", "das asco", "vete a morir",
                "suic√≠date", "m√°tate", "no vales nada", "eres una mierda", "despreciable",
                "asqueroso", "aberraci√≥n", "escupitajo", "lacra", "par√°sito", "cucaracha"
            ],
            'medium_risk': [
                "burla", "rid√≠culo", "verg√ºenza", "raro", "fen√≥meno", "bicho raro",
                "inadaptado", "antisocial", "extra√±o", "anormal", "loco", "chiflado",
                "payaso", "tonto", "bobo", "ignorante", "torpe", "incapaz", "d√©bil",
                "cobarde", "llorica"
            ],
            'context_phrases': [
                "todos se r√≠en de ti", "nadie quiere ser tu amigo", "siempre est√°s solo",
                "no tienes amigos", "eres invisible", "no perteneces aqu√≠",
                "mejor no vengas", "nadie te invit√≥", "sobras aqu√≠", "est√°s de m√°s",
                "no encajas", "eres el hazmerre√≠r", "todos hablan de ti"
            ],
            'work_context': [
                "redes sociales", "facebook", "instagram", "twitter", "publicar",
                "etiquetar", "compartir", "viral", "meme", "story", "post",
                "grupo", "chat", "clase", "escuela", "colegio", "compa√±eros",
                "universidad", "instituto"
            ]
        },
        "Infidelidades": {
            'high_risk': [
                "te amo", "te quiero", "mi amor", "amor m√≠o", "mi vida", "coraz√≥n",
                "besos", "te extra√±o", "te necesito", "eres especial", "√∫nico",
                "√∫nica", "no se lo digas", "secreto", "clandestino", "oculto",
                "amor prohibido", "relaci√≥n secreta", "aventura", "escapada",
                "mi alma gemela", "eres todo para m√≠"
            ],
            'medium_risk': [
                "cari√±o", "querido", "querida", "tesoro", "cielo", "precioso",
                "preciosa", "encanto", "dulzura", "ternura", "especial",
                "importante", "diferente", "comprensi√≥n", "conexi√≥n", "qu√≠mica",
                "atracci√≥n", "feeling"
            ],
            'context_phrases': [
                "entre nosotros", "nadie debe saber", "nuestro secreto", "solo t√∫ y yo",
                "cuando estemos solos", "no puede enterarse", "es complicado",
                "situaci√≥n dif√≠cil", "tengo pareja", "estoy casado", "estoy casada",
                "mi esposo no", "mi esposa no", "relaci√≥n complicada", "no es el momento"
            ],
            'work_context': [
                "esposo", "esposa", "marido", "mujer", "novio", "novia", "pareja",
                "familia", "casa", "hogar", "compromiso", "relaci√≥n", "matrimonio",
                "encuentro", "verse", "quedar", "cita", "hotel", "lugar privado",
                "escaparse", "mentir", "coartada", "excusa", "disimular"
            ]
        }
    }

def load_dictionary_from_file(uploaded_file):
    """Carga diccionario desde archivo subido con validaci√≥n mejorada"""
    dictionary = {
        'high_risk': [],
        'medium_risk': [], 
        'context_phrases': [],
        'work_context': []
    }
    
    try:
        if uploaded_file.name.endswith('.csv'):
            content = uploaded_file.read().decode('utf-8')
            reader = csv.DictReader(io.StringIO(content))
        else:
            st.error("‚ùå Solo se aceptan archivos .csv")
            return None
        
        expected_headers = ['termino', 'categoria']
        if not all(header in reader.fieldnames for header in expected_headers):
            st.error(f"‚ùå El archivo debe tener las columnas: {', '.join(expected_headers)}")
            st.error(f"üìã Columnas encontradas: {', '.join(reader.fieldnames)}")
            return None
        
        category_map = {
            'palabras_alta': 'high_risk',
            'palabras_media': 'medium_risk', 
            'frases_contexto': 'context_phrases',
            'contexto_laboral': 'work_context',
            'contexto_relacion': 'work_context',
            'contexto_financiero': 'work_context',
            'contexto_agresion': 'work_context',
            'contexto_emocional': 'work_context',
            'contexto_digital': 'work_context',
            'contexto_sustancias': 'work_context'
        }
        
        valid_categories = set(category_map.keys())
        loaded_terms = 0
        invalid_categories = set()
        
        for row in reader:
            if not row['termino'] or row['termino'].startswith('#'):
                continue
            
            term = row['termino'].strip().lower()
            category = row['categoria'].strip().lower()
            
            if category not in valid_categories:
                invalid_categories.add(category)
                continue
            
            mapped_category = category_map[category]
            if term and term not in dictionary[mapped_category]:
                dictionary[mapped_category].append(term)
                loaded_terms += 1
        
        if invalid_categories:
            st.warning(f"‚ö†Ô∏è Categor√≠as inv√°lidas ignoradas: {', '.join(invalid_categories)}")
        
        if loaded_terms > 0:
            st.success(f"‚úÖ Diccionario cargado: {loaded_terms} t√©rminos")
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Alto Riesgo", len(dictionary['high_risk']))
            with col2:
                st.metric("Riesgo Medio", len(dictionary['medium_risk']))
            with col3:
                st.metric("Contexto", len(dictionary['context_phrases']))
            with col4:
                st.metric("Laboral", len(dictionary['work_context']))
            
            return dictionary
        else:
            st.error("‚ùå No se pudieron cargar t√©rminos v√°lidos")
            return None
        
    except Exception as e:
        st.error(f"‚ùå Error al procesar archivo: {str(e)}")
        return None

def process_messages_in_batches(messages, analyzer, config, dictionary, detection_type, batch_size=50):
    """Procesa mensajes en lotes para mejor rendimiento"""
    total_batches = (len(messages) + batch_size - 1) // batch_size
    results = []
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for batch_num in range(total_batches):
        start_idx = batch_num * batch_size
        end_idx = min((batch_num + 1) * batch_size, len(messages))
        batch = messages[start_idx:end_idx]
        
        # Actualizar progreso
        progress = (batch_num + 1) / total_batches
        progress_bar.progress(progress)
        status_text.text(f"Procesando lote {batch_num + 1}/{total_batches} ({end_idx}/{len(messages)} mensajes)")
        
        # Procesar lote
        for i, (timestamp, sender, message) in enumerate(batch):
            risk, label, words, analysis_details, explanation = analyzer.analyze_message(
                message, sender, timestamp, config, dictionary, detection_type
            )
            
            results.append({
                'timestamp': timestamp,
                'sender': sender,
                'message': message,
                'risk_score': round(risk, 4),
                'label': label,
                'detected_words': ', '.join(words) if words else "",
                'explanation': explanation
            })
        
        # Peque√±a pausa para no sobrecargar
        time.sleep(0.1)
    
    progress_bar.empty()
    status_text.empty()
    
    return results

def main():
    # Header principal mejorado
    st.markdown("""
    <div class="main-header">
        <h1>üîç WhatsApp Analyzer 5.0 - Enhanced Edition</h1>
        <p>Sistema avanzado para detecci√≥n de patrones de comportamiento en chats</p>
        <small>Versi√≥n 5.0 - Con mejoras de rendimiento, visualizaciones avanzadas y tabla optimizada</small>
    </div>
    """, unsafe_allow_html=True)
    
    # Mostrar estado de las herramientas mejorado
    col1, col2 = st.columns(2)
    with col1:
        if SPACY_AVAILABLE:
            st.success("‚úÖ **An√°lisis NLP Completo** (spaCy + an√°lisis avanzado)")
        else:
            st.info("‚ÑπÔ∏è **An√°lisis Inteligente** (sin spaCy, pero completamente funcional)")
    
    with col2:
        if TEXTBLOB_AVAILABLE:
            st.success("‚úÖ **An√°lisis de Sentimientos** (TextBlob integrado)")
        else:
            st.info("‚ÑπÔ∏è **An√°lisis B√°sico de Sentimientos** (algoritmo propio)")
    
    # Tabs principales
    tab1, tab2, tab3 = st.tabs(["üîç An√°lisis", "üìñ Instructivo", "üìÑ Formato CSV"])
    
    with tab3:
        st.markdown("""
        ## üìã **FORMATO DEL ARCHIVO CSV DE DICCIONARIO**
        
        El archivo CSV debe tener **exactamente 2 columnas** con los siguientes encabezados:
        
        ```csv
        termino,categoria
        sexy,palabras_alta
        atractiva,palabras_media
        solos,frases_contexto
        jefe,contexto_laboral
        ```
        
        ### **Categor√≠as V√°lidas:**
        
        | Categor√≠a | Descripci√≥n | Peso en An√°lisis |
        |-----------|-------------|------------------|
        | `palabras_alta` | T√©rminos de alto riesgo | ‚ö†Ô∏è **Alto** (0.7-0.8) |
        | `palabras_media` | T√©rminos de riesgo medio | ‚ö° **Medio** (0.3-0.4) |
        | `frases_contexto` | Frases que dan contexto | üîç **Contextual** (0.5-0.6) |
        | `contexto_laboral` | T√©rminos de trabajo/profesional | üè¢ **Laboral** (0.3-0.5) |
        """)
    
    with tab2:
        st.markdown("""
        # üìñ **INSTRUCTIVO COMPLETO - WhatsApp Analyzer 5.0**
        
        ## üéØ **¬øQU√â HACE ESTA APLICACI√ìN?**
        
        Esta herramienta analiza conversaciones de WhatsApp para detectar patrones de comportamiento potencialmente problem√°ticos usando **an√°lisis inteligente de texto** con tecnolog√≠a NLP.
        
        ### **Nuevas Caracter√≠sticas v5.0:**
        - üìä **Tabla mejorada** para visualizar detecciones
        - ‚ö° **Procesamiento en lotes** para mejor rendimiento
        - üìà **M√©tricas avanzadas** y an√°lisis temporal
        - üîç **Filtros avanzados** para explorar resultados
        - üé® **Interfaz optimizada** con mejor UX
        
        ### **Tipos de Detecci√≥n:**
        
        | üîç Tipo | üìù Descripci√≥n | üéØ Detecta |
        |---------|----------------|-------------|
        | **üö® Acoso Sexual** | Comportamientos inapropiados | Lenguaje sexual, propuestas inapropiadas, acoso laboral |
        | **üò† CyberBullying** | Intimidaci√≥n y agresi√≥n digital | Insultos, amenazas, exclusi√≥n social, humillaci√≥n |
        | **üíî Infidelidades** | Indicios de relaciones extramaritales | Expresiones de amor oculto, citas secretas, doble vida |
        
        ## üõ†Ô∏è **C√ìMO USAR LA APLICACI√ìN**
        
        ### **Paso 1: Exportar Chat de WhatsApp**
        
        #### **üì± En Android:**
        1. Abre WhatsApp ‚Üí Chat espec√≠fico
        2. Toca **‚ãÆ** ‚Üí **M√°s** ‚Üí **Exportar chat**
        3. Selecciona **"Sin archivos multimedia"**
        4. Guarda el archivo `.txt`
        
        #### **üì± En iPhone:**
        1. Abre WhatsApp ‚Üí Chat espec√≠fico
        2. Toca el **nombre del contacto/grupo**
        3. **Exportar chat** ‚Üí **"Sin archivos multimedia"**
        4. Guarda el archivo `.txt`
        
        ### **Paso 2: Configurar y Analizar**
        
        1. **Selecciona tipo de detecci√≥n** (Acoso, Bullying, Infidelidades, etc.)
        2. **Configura sensibilidad** (Baja, Media, Alta)
        3. **Sube el archivo .txt** exportado
        4. **Revisa resultados** en la tabla mejorada
        5. **Descarga reportes** si es necesario
        
        ## üìä **NUEVAS CARACTER√çSTICAS DE LA TABLA**
        
        La tabla mejorada muestra:
        - **ID √∫nico** para cada detecci√≥n
        - **Fecha/Hora** formateada
        - **Remitente** identificado
        - **Vista previa del mensaje** (truncada para legibilidad)
        - **Puntuaci√≥n de riesgo** precisa (0.000-1.000)
        - **Nivel de riesgo** visual (üî¥ Alto, üü° Medio, üü¢ Bajo)
        - **T√©rminos detectados** espec√≠ficos
        - **An√°lisis detallado** explicativo (opcional)
        
        ## ‚ö° **MEJORAS DE RENDIMIENTO**
        
        - **Procesamiento en lotes**: Chats grandes se procesan eficientemente
        - **Cache inteligente**: Evita reprocesamiento innecesario
        - **Progreso detallado**: Indicadores en tiempo real
        - **Validaci√≥n robusta**: Mejor detecci√≥n de archivos WhatsApp
        
        ## üîç **FILTROS AVANZADOS**
        
        - **Por remitente**: Filtra mensajes espec√≠ficos
        - **Por rango de riesgo**: Ajusta sensibilidad de visualizaci√≥n
        - **B√∫squeda de texto**: Encuentra palabras espec√≠ficas
        - **Configuraci√≥n de l√≠mites**: Controla cantidad de resultados
        
        ## ‚öñÔ∏è **CONSIDERACIONES LEGALES Y √âTICAS**
        
        ### **üîí Privacidad:**
        - ‚úÖ **100% Local**: Todo se procesa en tu navegador
        - ‚úÖ **Sin almacenamiento**: Nada se guarda en servidores
        - ‚úÖ **Sin env√≠o de datos**: Completa privacidad
        
        ### **‚öñÔ∏è Uso Responsable:**
        - üìã **Solo con consentimiento** de las partes involucradas
        - üõ°Ô∏è **Cumplir leyes locales** de privacidad
        - üë®‚Äç‚öñÔ∏è **No es evidencia legal**: Requiere validaci√≥n profesional
        - üîç **Herramienta de apoyo**: Para investigaci√≥n preliminar
        
        ## üö® **SOLUCI√ìN DE PROBLEMAS**
        
        ### **‚ùå "No se pudieron extraer mensajes"**
        - Verifica formato de exportaci√≥n de WhatsApp
        - Aseg√∫rate de exportar "sin multimedia"
        - Valida que el archivo no est√© corrupto
        
        ### **‚ö° "An√°lisis lento"**
        - Chats >5000 mensajes pueden tardar varios minutos
        - El procesamiento en lotes mejora la experiencia
        - Usar sensibilidad "baja" es m√°s r√°pido
        
        ### **üìä "Muchos falsos positivos"**
        - Reduce sensibilidad o aumenta umbral
        - Usa filtros para revisar casos espec√≠ficos
        - Revisa manualmente los resultados
        
        ## ‚úÖ **RESUMEN R√ÅPIDO v5.0**
        
        1. **üì§ Exporta** chat (sin multimedia)
        2. **üéØ Selecciona** tipo de detecci√≥n
        3. **‚öôÔ∏è Configura** sensibilidad
        4. **üìÅ Sube** archivo .txt
        5. **üîÑ Analiza** (procesamiento mejorado)
        6. **üìä Explora** tabla de detecciones
        7. **üîç Filtra** resultados seg√∫n necesidad
        8. **üíæ Descarga** reportes completos
        
        **¬°Listo para el an√°lisis avanzado!** üöÄ
        """)
    
    with tab1:
        # Sidebar - Configuraci√≥n mejorada
        with st.sidebar:
            st.header("‚öôÔ∏è Configuraci√≥n del An√°lisis")
            
            detection_options = list(get_predefined_dictionaries().keys()) + ["Diccionario Personalizado"]
            detection_type = st.selectbox(
                "üéØ Tipo de Detecci√≥n",
                detection_options,
                help="Selecciona qu√© patr√≥n quieres detectar"
            )
            
            # Informaci√≥n del tipo seleccionado
            if detection_type != "Diccionario Personalizado":
                info_dict = {
                    "Acoso Sexual": "üö® Detecta insinuaciones inapropiadas, propuestas sexuales, acoso laboral",
                    "CyberBullying": "üò† Identifica insultos, amenazas, intimidaci√≥n, exclusi√≥n social", 
                    "Infidelidades": "üíî Encuentra expresiones rom√°nticas ocultas, citas secretas, enga√±os"
                }
                st.info(info_dict[detection_type])
            
            # Diccionario
            dictionary = None
            if detection_type == "Diccionario Personalizado":
                st.subheader("üìÅ Subir Diccionario CSV")
                
                with st.expander("üìã Ver formato requerido"):
                    st.code("""termino,categoria
sexy,palabras_alta
atractiva,palabras_media
solos,frases_contexto
jefe,contexto_laboral""")
                
                uploaded_dict = st.file_uploader(
                    "Selecciona archivo CSV",
                    type=['csv'],
                    help="Debe tener columnas: termino,categoria"
                )
                
                if uploaded_dict:
                    dictionary = load_dictionary_from_file(uploaded_dict)
                    if not dictionary:
                        st.stop()
                else:
                    st.warning("‚ö†Ô∏è Sube un diccionario CSV para continuar")
                    st.stop()
            else:
                dictionary = get_predefined_dictionaries()[detection_type]
                
                st.subheader("üìä Diccionario Cargado")
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("üî¥ Alto Riesgo", len(dictionary['high_risk']))
                    st.metric("üü° Riesgo Medio", len(dictionary['medium_risk']))
                with col2:
                    st.metric("üîç Contexto", len(dictionary['context_phrases']))
                    st.metric("üè¢ Laboral", len(dictionary['work_context']))
            
            st.divider()
            
            # Configuraci√≥n de sensibilidad
            st.subheader("üéöÔ∏è Sensibilidad del An√°lisis")
            sensitivity = st.select_slider(
                "Nivel de Sensibilidad",
                options=['baja', 'media', 'alta'],
                value='media',
                help="Baja: Menos falsos positivos | Alta: Detecta m√°s casos"
            )
            
            sensitivity_info = {
                'baja': "üü¢ Conservador - Solo casos evidentes (umbral: 0.75)",
                'media': "üü° Balanceado - Precisi√≥n √≥ptima (umbral: 0.60)", 
                'alta': "üî¥ Agresivo - Detecta casos sutiles (umbral: 0.45)"
            }
            st.info(sensitivity_info[sensitivity])
            
            custom_threshold = st.slider(
                "üéØ Umbral Personalizado",
                min_value=0.0,
                max_value=1.0,
                value=0.6,
                step=0.05,
                help="0.0 = Muy sensible | 1.0 = Muy estricto"
            )
            
            use_custom = st.checkbox("Usar umbral personalizado")
            
            st.divider()
            
            # Opciones avanzadas
            st.subheader("üîß Opciones Avanzadas")
            
            show_explanations = st.checkbox(
                "üß† Mostrar Explicaciones Detalladas",
                value=True,
                help="Incluye explicaciones de por qu√© se detect√≥ cada caso"
            )
            
            max_results = st.selectbox(
                "üìä M√°ximo de Evidencias en Tabla",
                [25, 50, 100, 200, "Todas"],
                index=1,
                help="Limita resultados en tabla para mejor rendimiento"
            )
            
            batch_size = st.selectbox(
                "‚ö° Tama√±o de Lote de Procesamiento",
                [25, 50, 100, 200],
                index=1,
                help="Lotes m√°s grandes = m√°s r√°pido, pero menos feedback"
            )
        
        # √Årea principal de contenido
        st.header("üì§ Subir Archivo de Chat")
        
        # Instrucciones r√°pidas
        with st.expander("üìß ¬øC√≥mo exportar chat de WhatsApp?"):
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("""
                **üì± Android:**
                1. Abre el chat en WhatsApp
                2. Toca ‚ãÆ ‚Üí M√°s ‚Üí Exportar chat
                3. Selecciona "Sin archivos multimedia"
                4. Guarda el archivo .txt
                """)
            with col2:
                st.markdown("""
                **üì± iPhone:**
                1. Abre el chat en WhatsApp
                2. Toca el nombre del contacto
                3. Exportar chat ‚Üí Sin archivos multimedia
                4. Guarda el archivo .txt
                """)
        
        uploaded_file = st.file_uploader(
            "üìÅ Selecciona el archivo de chat (.txt)",
            type=['txt'],
            help="Debe ser una exportaci√≥n de WhatsApp sin archivos multimedia"
        )
        
        # Procesar archivo si est√° disponible
        if uploaded_file and dictionary:
            try:
                content = uploaded_file.read().decode('utf-8')
                
                # Validaci√≥n mejorada
                is_valid, validation_message = validate_whatsapp_file(content)
                
                if not is_valid:
                    st.error(f"‚ùå **{validation_message}**")
                    st.info("""
                    **Posibles causas:**
                    - El archivo no es una exportaci√≥n v√°lida de WhatsApp
                    - Formato de fecha no reconocido
                    - Archivo corrupto o modificado
                    
                    **Soluci√≥n:**
                    - Verifica que sea un archivo .txt exportado directamente de WhatsApp
                    - Aseg√∫rate de seleccionar "Sin archivos multimedia" al exportar
                    """)
                    st.stop()
                
                st.success(f"‚úÖ **{validation_message}**")
                
                if len(content.strip()) < 100:
                    st.error("‚ùå El archivo parece estar vac√≠o o muy corto")
                    st.stop()
                
                with st.spinner("üîç Extrayendo mensajes del chat..."):
                    messages = extract_messages_from_text(content)
                
                if not messages:
                    st.error("""
                    ‚ùå **No se pudieron extraer mensajes del archivo.**
                    
                    **Posibles causas:**
                    - El archivo no es una exportaci√≥n v√°lida de WhatsApp
                    - Formato de fecha no reconocido
                    - Archivo corrupto o modificado
                    
                    **Soluci√≥n:**
                    - Verifica que sea un archivo .txt exportado directamente de WhatsApp
                    - Aseg√∫rate de seleccionar "Sin archivos multimedia" al exportar
                    """)
                    st.stop()
                
                st.success(f"‚úÖ **{len(messages)} mensajes extra√≠dos correctamente**")
                
                # Vista previa de mensajes
                with st.expander(f"üëÄ Vista previa de mensajes (primeros 5 de {len(messages)})"):
                    for i, (timestamp, sender, message) in enumerate(messages[:5]):
                        st.markdown(f"""
                        <div style="background: #f8f9fa; padding: 1rem; margin: 0.5rem 0; border-radius: 8px; border-left: 3px solid #667eea;">
                            <strong>üìÖ {timestamp}</strong> | <strong>üë§ {sender}</strong><br>
                            üí¨ {message[:100]}{'...' if len(message) > 100 else ''}
                        </div>
                        """, unsafe_allow_html=True)
                
                # Configurar an√°lisis
                config = setup_sensitivity(
                    sensitivity, 
                    custom_threshold if use_custom else None
                )
                
                # Informaci√≥n del an√°lisis
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.info(f"üéØ **Detectando:** {detection_type}")
                with col2:
                    st.info(f"üéöÔ∏è **Sensibilidad:** {sensitivity}")
                with col3:
                    st.info(f"üéØ **Umbral:** {config['threshold']:.2f}")
                
                # Inicializar analizador
                analyzer = SmartTextAnalyzer()
                
                # Procesar mensajes con lotes mejorados
                st.subheader("üîÑ Procesando Mensajes...")
                
                with st.container():
                    st.markdown("""
                    <div class="progress-container">
                        <h4>‚ö° An√°lisis en Progreso</h4>
                        <p>Procesando mensajes en lotes para optimizar el rendimiento...</p>
                    </div>
                    """, unsafe_allow_html=True)
                    
                    results = process_messages_in_batches(
                        messages, analyzer, config, dictionary, detection_type, batch_size
                    )
                
                # Crear DataFrame de resultados
                results_df = pd.DataFrame(results)
                
                # Calcular m√©tricas avanzadas
                advanced_metrics = calculate_advanced_metrics(results_df)
                alerts = generate_smart_alerts(results_df, detection_type)
                recommendations = generate_recommendations(results_df, detection_type)
                
                # Mostrar alertas si las hay
                if alerts:
                    st.subheader("üö® Alertas del Sistema")
                    for alert in alerts:
                        if alert['level'] == 'critical':
                            st.markdown(f"""
                            <div class="alert-critical">
                                <h4>üö® ALERTA CR√çTICA</h4>
                                <p>{alert['message']}</p>
                            </div>
                            """, unsafe_allow_html=True)
                        elif alert['level'] == 'warning':
                            st.markdown(f"""
                            <div class="alert-warning">
                                <h4>‚ö†Ô∏è ADVERTENCIA</h4>
                                <p>{alert['message']}</p>
                            </div>
                            """, unsafe_allow_html=True)
                        else:
                            st.markdown(f"""
                            <div class="alert-info">
                                <h4>‚ÑπÔ∏è INFORMACI√ìN</h4>
                                <p>{alert['message']}</p>
                            </div>
                            """, unsafe_allow_html=True)
                
                # Dashboard de m√©tricas mejorado
                st.header("üìà Resultados del An√°lisis")
                create_enhanced_metric_dashboard(results_df)
                
                # Evaluaci√≥n del riesgo general
                detected_count = len(results_df[results_df['label'] == 'DETECTADO'])
                percentage = (detected_count / len(results_df)) * 100 if len(results_df) > 0 else 0
                
                if percentage == 0:
                    st.success("‚úÖ **Excelente**: No se detectaron patrones problem√°ticos")
                elif percentage < 5:
                    st.info("üü¢ **Bajo Riesgo**: Pocos casos detectados, revisar manualmente")
                elif percentage < 15:
                    st.warning("üü° **Riesgo Moderado**: Revisar casos detectados cuidadosamente")
                else:
                    st.error("üî¥ **Alto Riesgo**: M√∫ltiples detecciones, requiere atenci√≥n inmediata")
                
                # Mostrar visualizaciones mejoradas
                if detected_count > 0:
                    st.header("üìä An√°lisis Visual Avanzado")
                    create_enhanced_visualizations(results_df, detection_type)
                    
                    # An√°lisis por remitente mejorado
                    st.subheader("üë• An√°lisis por Remitente")
                    sender_stats = results_df.groupby('sender').agg({
                        'risk_score': ['count', 'mean', 'max'],
                        'label': lambda x: (x == 'DETECTADO').sum()
                    }).round(3)
                    
                    sender_stats.columns = ['Total Mensajes', 'Riesgo Promedio', 'Riesgo M√°ximo', 'Detecciones']
                    sender_stats = sender_stats.sort_values('Detecciones', ascending=False)
                    
                    st.dataframe(
                        sender_stats,
                        use_container_width=True,
                        column_config={
                            "Total Mensajes": st.column_config.NumberColumn("üì± Total"),
                            "Riesgo Promedio": st.column_config.NumberColumn("‚öñÔ∏è Promedio", format="%.3f"),
                            "Riesgo M√°ximo": st.column_config.NumberColumn("üìä M√°ximo", format="%.3f"),
                            "Detecciones": st.column_config.NumberColumn("üö® Detectados")
                        }
                    )
                    
                    # TABLA MEJORADA DE DETECCIONES - CARACTER√çSTICA PRINCIPAL
                    st.header("üîç Tabla de Detecciones Mejorada")
                    
                    detected_df = results_df[results_df['label'] == 'DETECTADO'].copy()
                    detected_df = detected_df.sort_values('risk_score', ascending=False)
                    
                    # Filtros din√°micos para la tabla
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        available_senders = detected_df['sender'].unique().tolist()
                        sender_filter = st.multiselect(
                            "üë§ Filtrar por remitente:",
                            options=available_senders,
                            default=available_senders,
                            help="Selecciona remitentes espec√≠ficos"
                        )
                    
                    with col2:
                        risk_threshold = st.slider(
                            "‚öñÔ∏è Riesgo m√≠nimo:",
                            min_value=0.0,
                            max_value=1.0,
                            value=config['threshold'],
                            step=0.05,
                            help="Filtrar por nivel de riesgo"
                        )
                    
                    with col3:
                        word_filter = st.text_input(
                            "üîç Buscar palabra:",
                            placeholder="Ej: sexy, amor, secreto...",
                            help="Busca mensajes que contengan esta palabra"
                        )
                    
                    # Aplicar filtros a la tabla
                    filtered_df = detected_df[
                        (detected_df['sender'].isin(sender_filter)) &
                        (detected_df['risk_score'] >= risk_threshold)
                    ]
                    
                    if word_filter:
                        filtered_df = filtered_df[
                            filtered_df['message'].str.contains(word_filter, case=False, na=False) |
                            filtered_df['detected_words'].str.contains(word_filter, case=False, na=False)
                        ]
                    
                    # Mostrar tabla mejorada
                    max_table_results = max_results if max_results != "Todas" else len(filtered_df)
                    create_enhanced_detections_table(
                        filtered_df, 
                        show_explanations=show_explanations, 
                        max_results=max_table_results
                    )
                    
                else:
                    st.success("‚úÖ **¬°Excelente noticia!** No se detectaron patrones sospechosos en la conversaci√≥n")
                    
                    # Mostrar estad√≠sticas b√°sicas aunque no haya detecciones
                    st.subheader("üìä Estad√≠sticas Generales")
                    
                    sender_counts = results_df['sender'].value_counts()
                    if len(sender_counts) > 1:
                        fig_senders = px.bar(
                            x=sender_counts.index,
                            y=sender_counts.values,
                            title="üì± Mensajes por Remitente",
                            labels={'x': 'Remitente', 'y': 'Cantidad de Mensajes'},
                            color_discrete_sequence=['#667eea']
                        )
                        fig_senders.update_layout(
                            plot_bgcolor='rgba(0,0,0,0)',
                            paper_bgcolor='rgba(0,0,0,0)',
                        )
                        st.plotly_chart(fig_senders, use_container_width=True)
                
                # Mostrar m√©tricas avanzadas si est√°n disponibles
                if advanced_metrics:
                    st.subheader("üìä M√©tricas Avanzadas")
                    
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        if 'peak_risk_hour' in advanced_metrics:
                            st.metric(
                                "üïê Hora de Mayor Riesgo", 
                                f"{advanced_metrics['peak_risk_hour']}:00",
                                help="Hora del d√≠a con mayor actividad de riesgo"
                            )
                    
                    with col2:
                        if 'risk_trend' in advanced_metrics:
                            trend_emoji = "üìà" if advanced_metrics['risk_trend'] == 'increasing' else "üìâ"
                            st.metric(
                                f"{trend_emoji} Tendencia de Riesgo", 
                                advanced_metrics['risk_trend'].title(),
                                help="Tendencia del riesgo a lo largo del tiempo"
                            )
                    
                    with col3:
                        if 'top_risk_words' in advanced_metrics and advanced_metrics['top_risk_words']:
                            top_word = list(advanced_metrics['top_risk_words'].keys())[0]
                            top_count = advanced_metrics['top_risk_words'][top_word]
                            st.metric(
                                "üîç Palabra M√°s Frecuente", 
                                f"{top_word} ({top_count}x)",
                                help="T√©rmino m√°s detectado en el an√°lisis"
                            )
                
                # Mostrar recomendaciones
                if recommendations:
                    st.subheader("üí° Recomendaciones del Sistema")
                    
                    for i, rec in enumerate(recommendations):
                        st.markdown(f"""
                        <div class="recommendation-box">
                            <strong>{i+1}.</strong> {rec}
                        </div>
                        """, unsafe_allow_html=True)
                
                # Secci√≥n de descarga mejorada
                st.header("üíæ Descargar Resultados")
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    # CSV completo mejorado
                    csv_buffer = io.StringIO()
                    
                    # Agregar metadatos al CSV
                    csv_buffer.write(f"# WhatsApp Analyzer v5.0 - An√°lisis Completo\n")
                    csv_buffer.write(f"# Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                    csv_buffer.write(f"# Tipo: {detection_type}\n")
                    csv_buffer.write(f"# Total Mensajes: {len(results_df)}\n")
                    csv_buffer.write(f"# Detecciones: {detected_count}\n")
                    csv_buffer.write(f"# Porcentaje: {percentage:.2f}%\n")
                    csv_buffer.write(f"# Umbral: {config['threshold']:.3f}\n")
                    csv_buffer.write("#\n")
                    
                    results_df.to_csv(csv_buffer, index=False, encoding='utf-8')
                    csv_data = csv_buffer.getvalue()
                    
                    filename = f"analisis_completo_{detection_type.lower().replace(' ', '_')}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
                    
                    st.download_button(
                        label="üìÑ Descargar An√°lisis Completo (CSV)",
                        data=csv_data,
                        file_name=filename,
                        mime="text/csv",
                        help="Incluye todos los mensajes analizados con metadatos"
                    )
                
                with col2:
                    # Solo detecciones mejorado
                    if detected_count > 0:
                        detected_csv = io.StringIO()
                        
                        # Metadatos para detecciones
                        detected_csv.write(f"# WhatsApp Analyzer v5.0 - Solo Detecciones\n")
                        detected_csv.write(f"# Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                        detected_csv.write(f"# Tipo: {detection_type}\n")
                        detected_csv.write(f"# Detecciones: {detected_count}\n")
                        detected_csv.write(f"# Umbral: {config['threshold']:.3f}\n")
                        detected_csv.write("#\n")
                        
                        detected_df.to_csv(detected_csv, index=False, encoding='utf-8')
                        detected_data = detected_csv.getvalue()
                        
                        filename_detected = f"solo_detecciones_{detection_type.lower().replace(' ', '_')}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
                        
                        st.download_button(
                            label="üö® Descargar Solo Detecciones (CSV)",
                            data=detected_data,
                            file_name=filename_detected,
                            mime="text/csv",
                            help="Solo mensajes detectados como problem√°ticos"
                        )
                    else:
                        st.info("üìä No hay detecciones para descargar")
                
                with col3:
                    # Reporte ejecutivo mejorado
                    report_data = f"""REPORTE EJECUTIVO - WHATSAPP ANALYZER V5.0
=========================================================
Fecha de an√°lisis: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
Archivo analizado: {uploaded_file.name}
Tipo de detecci√≥n: {detection_type}
Sensibilidad: {sensitivity}
Umbral usado: {config['threshold']:.3f}

RESUMEN EJECUTIVO:
{"="*50}
- Total de mensajes analizados: {len(results_df):,}
- Mensajes detectados: {detected_count:,}
- Porcentaje de detecci√≥n: {percentage:.2f}%
- Riesgo promedio: {results_df['risk_score'].mean():.4f}
- Riesgo m√°ximo encontrado: {results_df['risk_score'].max():.4f}

EVALUACI√ìN DE RIESGO:
{"="*50}
{"CR√çTICO - Requiere atenci√≥n inmediata" if percentage > 30 else
 "ALTO - Revisar cuidadosamente" if percentage > 15 else
 "MODERADO - Monitoreo recomendado" if percentage > 5 else
 "BAJO - Situaci√≥n controlada" if percentage > 0 else
 "M√çNIMO - No se detectaron problemas"}

AN√ÅLISIS POR REMITENTE:
{"="*50}
{results_df.groupby('sender').agg({
    'risk_score': ['count', 'mean', 'max'],
    'label': lambda x: (x == 'DETECTADO').sum()
}).to_string() if len(results_df) > 0 else 'No hay datos'}

ALERTAS DEL SISTEMA:
{"="*50}
{chr(10).join([f"- {alert['message']}" for alert in alerts]) if alerts else "No hay alertas cr√≠ticas"}

RECOMENDACIONES:
{"="*50}
{chr(10).join([f"- {rec}" for rec in recommendations]) if recommendations else "No hay recomendaciones espec√≠ficas"}

M√âTRICAS AVANZADAS:
{"="*50}
{"- Hora de mayor riesgo: " + str(advanced_metrics.get('peak_risk_hour', 'N/A')) + ":00" if 'peak_risk_hour' in advanced_metrics else ""}
{"- Tendencia de riesgo: " + advanced_metrics.get('risk_trend', 'N/A').title() if 'risk_trend' in advanced_metrics else ""}
{"- Palabras m√°s frecuentes: " + str(list(advanced_metrics.get('top_risk_words', {}).keys())[:3]) if 'top_risk_words' in advanced_metrics else ""}

TECNOLOG√çAS UTILIZADAS:
{"="*50}
- Motor de an√°lisis: WhatsApp Analyzer v5.0 Enhanced
- spaCy NLP: {'Disponible' if SPACY_AVAILABLE else 'No disponible'}
- TextBlob Sentimientos: {'Disponible' if TEXTBLOB_AVAILABLE else 'No disponible'}
- An√°lisis contextual: Activado
- Detecci√≥n de patrones: Activada
- Procesamiento en lotes: Activado ({batch_size} mensajes por lote)

CONFIGURACI√ìN UTILIZADA:
{"="*50}
- Diccionario: {detection_type}
- T√©rminos de alto riesgo: {len(dictionary.get('high_risk', []))}
- T√©rminos de riesgo medio: {len(dictionary.get('medium_risk', []))}
- Frases de contexto: {len(dictionary.get('context_phrases', []))}
- Contexto laboral: {len(dictionary.get('work_context', []))}

DISCLAIMER LEGAL:
{"="*50}
Este reporte fue generado autom√°ticamente por WhatsApp Analyzer v5.0
y debe ser utilizado √∫nicamente como herramienta de apoyo. Los resultados
requieren validaci√≥n manual y no constituyen evidencia legal definitiva.
El uso de esta herramienta debe cumplir con las leyes locales de privacidad
y protecci√≥n de datos.

Procesamiento realizado 100% localmente - Sin env√≠o de datos externos
"""
                    
                    filename_report = f"reporte_ejecutivo_{detection_type.lower().replace(' ', '_')}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
                    
                    st.download_button(
                        label="üìã Descargar Reporte Ejecutivo (TXT)",
                        data=report_data,
                        file_name=filename_report,
                        mime="text/plain",
                        help="Reporte ejecutivo completo con an√°lisis y recomendaciones"
                    )
                
                # Informaci√≥n adicional sobre los archivos
                st.info("""
                üìÅ **Informaci√≥n sobre las descargas:**
                - **CSV Completo**: Incluye todos los mensajes con puntuaciones y metadatos
                - **CSV Detecciones**: Solo mensajes detectados para revisi√≥n r√°pida  
                - **Reporte Ejecutivo**: Resumen profesional con recomendaciones y an√°lisis
                """)
            
            except Exception as e:
                st.error(f"‚ùå **Error al procesar el archivo:**\n\n{str(e)}")
                logger.error(f"Error en an√°lisis: {str(e)}")
                st.info("""
                üí° **Posibles soluciones:**
                - Verifica que el archivo sea una exportaci√≥n v√°lida de WhatsApp
                - Aseg√∫rate de que el archivo no est√© corrupto
                - Intenta con un chat m√°s peque√±o para probar
                - Verifica que el archivo tenga la codificaci√≥n correcta (UTF-8)
                - Revisa que el formato de fecha sea compatible
                """)
    
    # Footer mejorado con informaci√≥n importante
    st.markdown("---")
    
    # Usar columnas de Streamlit en lugar de CSS grid
    st.markdown("""
    <div style="text-align: center; color: #666; padding: 20px; background: linear-gradient(145deg, #f8f9fa, #e9ecef); border-radius: 10px; margin-top: 2rem;">
        <h4>üîí Privacidad y Seguridad - WhatsApp Analyzer v5.0</h4>
    </div>
    """, unsafe_allow_html=True)
    
    # Usar columnas nativas de Streamlit para mejor compatibilidad
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown("""
        <div style="text-align: center; padding: 15px; background: #f8f9fa; border-radius: 8px; margin: 10px 5px;">
            <h5 style="color: #28a745; margin-bottom: 10px;">‚úÖ Procesamiento 100% Local</h5>
            <p style="font-size: 0.9em; color: #666; margin: 0;">Todos los archivos se procesan en tu navegador. No se env√≠an datos a servidores externos.</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div style="text-align: center; padding: 15px; background: #f8f9fa; border-radius: 8px; margin: 10px 5px;">
            <h5 style="color: #17a2b8; margin-bottom: 10px;">üóëÔ∏è Sin Almacenamiento</h5>
            <p style="font-size: 0.9em; color: #666; margin: 0;">No guardamos ninguna conversaci√≥n ni archivo. Todo se elimina al cerrar la aplicaci√≥n.</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("""
        <div style="text-align: center; padding: 15px; background: #f8f9fa; border-radius: 8px; margin: 10px 5px;">
            <h5 style="color: #ffc107; margin-bottom: 10px;">‚öñÔ∏è Uso Responsable</h5>
            <p style="font-size: 0.9em; color: #666; margin: 0;">Esta herramienta debe usarse √∫nicamente con fines leg√≠timos y respetando la privacidad.</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        st.markdown("""
        <div style="text-align: center; padding: 15px; background: #f8f9fa; border-radius: 8px; margin: 10px 5px;">
            <h5 style="color: #6f42c1; margin-bottom: 10px;">üî¨ Herramienta de Apoyo</h5>
            <p style="font-size: 0.9em; color: #666; margin: 0;">Los resultados requieren validaci√≥n manual y no constituyen evidencia legal definitiva.</p>
        </div>
        """, unsafe_allow_html=True)
    
    # Secci√≥n de nuevas caracter√≠sticas
    st.markdown("""
    <div style="text-align: center; padding: 20px; background: linear-gradient(145deg, #e8f5e8, #d4edda); border-radius: 10px; margin: 20px 0; border: 1px solid #c3e6cb;">
        <h5 style="color: #155724; margin-bottom: 15px;">üÜï Nuevas Caracter√≠sticas v5.0</h5>
        <p style="font-size: 1.1em; margin: 0;">
            <strong style="color: #28a745;">üìä Tabla Mejorada</strong> ‚Ä¢ 
            <strong style="color: #17a2b8;">‚ö° Procesamiento en Lotes</strong> ‚Ä¢ 
            <strong style="color: #6f42c1;">üîç Filtros Avanzados</strong> ‚Ä¢ 
            <strong style="color: #e83e8c;">üìà M√©tricas Avanzadas</strong> ‚Ä¢ 
            <strong style="color: #fd7e14;">üé® Interfaz Optimizada</strong>
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # Footer final
    st.markdown("""
    <div style="text-align: center; padding: 15px; color: #6c757d;">
        <small><em>WhatsApp Analyzer v5.0 Enhanced Edition - Optimizado para Streamlit Cloud</em></small>
    </div>
    """, unsafe_allow_html=True)

def get_csv_format_instructions():
    """Retorna las instrucciones del formato CSV actualizadas"""
    return """
    ## üìã **FORMATO DEL ARCHIVO CSV DE DICCIONARIO - v5.0**
    
    El archivo CSV debe tener **exactamente 2 columnas** con los siguientes encabezados:
    
    ```csv
    termino,categoria
    sexy,palabras_alta
    atractiva,palabras_media
    solos,frases_contexto
    jefe,contexto_laboral
    ```
    
    ### **Categor√≠as V√°lidas:**
    
    | Categor√≠a | Descripci√≥n | Peso en An√°lisis | Ejemplos |
    |-----------|-------------|------------------|----------|
    | `palabras_alta` | T√©rminos de alto riesgo | ‚ö†Ô∏è **Alto** (0.7-0.8) | sexy, desnudo, sexual |
    | `palabras_media` | T√©rminos de riesgo medio | ‚ö° **Medio** (0.3-0.4) | atractiva, bonita, cari√±o |
    | `frases_contexto` | Frases que dan contexto | üîç **Contextual** (0.5-0.6) | solos, secreto, privado |
    | `contexto_laboral` | T√©rminos de trabajo/profesional | üè¢ **Laboral** (0.3-0.5) | jefe, oficina, ascenso |
    | `contexto_relacion` | T√©rminos de relaciones | ‚ù§Ô∏è **Relacional** (0.4) | novio, pareja, matrimonio |
    | `contexto_financiero` | T√©rminos financieros | üí∞ **Financiero** (0.4) | dinero, pr√©stamo, deuda |
    | `contexto_agresion` | T√©rminos agresivos | üò† **Agresivo** (0.6) | odio, matar, venganza |
    | `contexto_emocional` | Expresiones emocionales | üò¢ **Emocional** (0.3) | tristeza, alegr√≠a, miedo |
    | `contexto_digital` | T√©rminos digitales/redes | üì± **Digital** (0.3) | facebook, instagram, viral |
    | `contexto_sustancias` | Referencias a sustancias | üö´ **Sustancias** (0.5) | drogas, alcohol, fumar |
    
    ### **Ejemplo Completo Mejorado:**
    ```csv
    termino,categoria
    # T√©rminos de alto riesgo
    sexy,palabras_alta
    desnudo,palabras_alta
    sexual,palabras_alta
    # T√©rminos de riesgo medio
    hermosa,palabras_media
    atractiva,palabras_media
    bonita,palabras_media
    # Frases de contexto
    solos,frases_contexto
    secreto,frases_contexto
    privado,frases_contexto
    # Contexto laboral
    jefe,contexto_laboral
    oficina,contexto_laboral
    ascenso,contexto_laboral
    ```
    
    ### **Notas Importantes:**
    - L√≠neas que empiecen con `#` son ignoradas (comentarios)
    - Los t√©rminos se procesan en min√∫sculas autom√°ticamente
    - No incluir t√©rminos duplicados
    - Usar codificaci√≥n UTF-8 para caracteres especiales
    """

# Funci√≥n para ejecutar tests automatizados
def run_automated_tests():
    """Tests automatizados para validar funcionamiento"""
    try:
        # Test de parsing de mensajes
        test_message = "15/01/24, 2:28 p. m. - Juan: Hola, ¬øc√≥mo est√°s?"
        messages = extract_messages_from_text(test_message)
        assert len(messages) == 1, "Error en parsing b√°sico"
        
        # Test de an√°lisis
        analyzer = SmartTextAnalyzer()
        test_dict = {'high_risk': ['test'], 'medium_risk': [], 'context_phrases': [], 'work_context': []}
        config = {'threshold': 0.5}
        
        score, label, words, analysis, explanation = analyzer.analyze_message(
            "test message", "sender", "timestamp", config, test_dict, "Test"
        )
        
        assert isinstance(score, float), "Score debe ser float"
        assert label in ['DETECTADO', 'NO DETECTADO'], "Label inv√°lido"
        
        st.success("‚úÖ Todos los tests automatizados pasaron correctamente")
        return True
        
    except Exception as e:
        st.error(f"‚ùå Error en tests automatizados: {str(e)}")
        logger.error(f"Error en tests: {str(e)}")
        return False

if __name__ == "__main__":
    try:
        # Ejecutar tests automatizados en desarrollo
        if st.sidebar.button("üß™ Ejecutar Tests Automatizados", help="Ejecuta validaciones del sistema"):
            with st.spinner("üîç Ejecutando tests automatizados..."):
                run_automated_tests()
        
        # Ejecutar aplicaci√≥n principal
        main()
        
    except Exception as e:
        st.error(f"‚ùå **Error cr√≠tico en la aplicaci√≥n:**\n\n{str(e)}")
        logger.critical(f"Error cr√≠tico: {str(e)}")
        st.info("""
        üîß **Para reportar este error:**
        1. Toma una captura de pantalla de este mensaje
        2. Incluye informaci√≥n sobre el archivo que intentabas analizar
        3. Describe los pasos que llevaron al error
        
        üîÑ **Para intentar solucionarlo:**
        1. Recarga la p√°gina (F5)
        2. Verifica que el archivo sea una exportaci√≥n v√°lida de WhatsApp
        3. Intenta con un archivo m√°s peque√±o
        """)
